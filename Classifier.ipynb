{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP requests classificator using HTTP dataset CSIC 2010\n",
    "\n",
    "90 % of combined normal and anomalous data are used for training, and the rest 10 % for testing. The Linear SVM is used for classification because it achieved the best result from a few classificators tried on this dataset.\n",
    "<br>\n",
    "<br>\n",
    "Data files from HTTP dataset CSIC 2010 are loaded and transformed into a list of HTTP requests containing some relevant data (e.g., lines starting with PUT, GET or POST). Then these lists are vectorized by TfidfVectorizer. Data set is randomly split to train and test data. Finally the example of the classification of some new HTTP traffic request is shown.\n",
    "## Conclusion\n",
    "I believe that this classifier can be used in production because it achieved 0.9997 accuracy on this dataset with only two detection errors using Linear SVM. Moreover, Linear SVM is significantly faster to train in comparison with some more complex classifiers (e.g., Random Forest Classifier, SVM with different kernel settings, Complement Naive Bayes ...) and also fast to predict compared to KNN classifier, for instance.\n",
    "\n",
    "\n",
    "## Online resources\n",
    "http://www.isi.csic.es/dataset/\n",
    "<br>\n",
    "https://www.tutorialspoint.com/http/http_requests.htm\n",
    "<br>\n",
    "https://github.com/Monkey-D-Groot/Machine-Learning-on-CSIC-2010\n",
    "<br>\n",
    "https://stackoverflow.com/a/29788612\n",
    "<br>\n",
    "<br>\n",
    "scikit-learn documentation, especially:\n",
    "<br>\n",
    "- https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "<br>\n",
    "- https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files\n",
    "normal_traffic_file_1 = 'normalTrafficTraining.txt'\n",
    "normal_traffic_file_2 = 'normalTrafficTest.txt'\n",
    "anomalous_traffic_file = 'anomalousTrafficTest.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and remove newlines characters\n",
    "def load_data(file_name):\n",
    "    file = open(file_name, 'r')\n",
    "    contents = file.read().split('\\n')\n",
    "    file.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normal and anomalous data into seperate lists\n",
    "normal_traffic = load_data(normal_traffic_file_1) + load_data(normal_traffic_file_2)\n",
    "anomalous_traffic = load_data(anomalous_traffic_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of http requests\n",
    "def create_requests_list(traffic_list):\n",
    "    traffic_requests = []\n",
    "    for line_num in range(len(traffic_list)):\n",
    "        line = traffic_list[line_num]\n",
    "        if line.startswith('GET'):\n",
    "            # Remove unnecessary white spaces and uppercase\n",
    "            line = line.lower().replace(' ', '')\n",
    "            traffic_requests.append(line)\n",
    "        elif line.startswith('POST') or line.startswith('PUT'):\n",
    "            request_str = line\n",
    "            while not line.startswith('Content-Length:'):\n",
    "                line_num += 1\n",
    "                line = traffic_list[line_num]\n",
    "            # Second line below 'Content-Length' may be relevant\n",
    "            request_str = request_str + traffic_list[line_num + 2]\n",
    "            request_str = request_str.lower().replace(' ', '')\n",
    "            traffic_requests.append(request_str)\n",
    "    return traffic_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_traffic_requests = create_requests_list(normal_traffic)\n",
    "anomalous_traffic_requests = create_requests_list(anomalous_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class normal: 1\n",
    "# Class anomalous: 0\n",
    "labels_normal = [1] * len(normal_traffic_requests)\n",
    "labels_anomalous = [0] * len(anomalous_traffic_requests)\n",
    "\n",
    "requests_all = normal_traffic_requests + anomalous_traffic_requests\n",
    "labels_all = labels_normal + labels_anomalous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization of text data\n",
    "# Could adjust TfidfVectorizer ngram_range settings, (5,5) works best in this case\n",
    "vectorizer = TfidfVectorizer(analyzer = \"char\", ngram_range = (5, 5))\n",
    "X = vectorizer.fit_transform(requests_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_all, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Linear SVM:  0.9997939631193984\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "score_test = accuracy_score(y_test, y_pred)\n",
    "print(\"Score Linear SVM: \", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[2560    2]\n",
      " [   0 7145]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomalous\n"
     ]
    }
   ],
   "source": [
    "# The example of classification of some new samples in file sample_traffic.txt\n",
    "sample_traffic_file = 'sample_traffic.txt'\n",
    "sample_traffic = load_data(sample_traffic_file)\n",
    "traffic_request = create_requests_list(sample_traffic)\n",
    "X_sample = vectorizer.transform(traffic_request)\n",
    "sample_pred = clf.predict(X_sample)\n",
    "for result in sample_pred:\n",
    "    if result == 0:\n",
    "        print('anomalous')\n",
    "    else:\n",
    "        print('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
